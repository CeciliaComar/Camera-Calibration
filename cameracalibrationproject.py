# -*- coding: utf-8 -*-
"""CameraCalibrationProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UjcY_WK2VAJb_ZFnQKU6YrwSFVMYijlJ

#CVPR Project 1 (Calibration)
"""

from matplotlib import pyplot as plt
import os
import numpy as np
import cv2
from google.colab import drive

"""## Load images (load only one set of images at a time)

### Load assignment images
"""

drive.mount('/content/drive/', force_remount=True)
GDrivePath = '/content/drive/MyDrive/'
folderpath = GDrivePath + 'CameraCalibrationProject/images/images/'

images = []

for i in range(20):
    filepath = folderpath + f'image{i:02}.tiff'
    image = cv2.imread(filepath)
    images.append(image)

images_array = np.array(images)

grid_size = (8, 11)
rows, cols = 8,11
square_size = 11

rect_width = 99
rect_height = 44
parallelepiped_depth = 60

chosenImage = folderpath + 'image11.tiff'

"""###Load smartphone images"""

drive.mount('/content/drive/', force_remount=True)
GDrivePath = '/content/drive/MyDrive/'
folderpath = GDrivePath + 'CameraCalibrationProject/smartphoneImages/'

images = []

for i in range(20):
    filepath = folderpath + f'colored_image{i:02}.jpg'
    image = cv2.imread(filepath)
    images.append(image)


images_array = np.array(images)

grid_size = (7, 10)
rows, cols = 7,10
square_size = 20

rect_width = 180
rect_height = 80
parallelepiped_depth = 60

chosenImage = folderpath + 'colored_image11.jpg'

"""## Detect and display checkerboard corners

"""

criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 100, 0.001)
corners_array = []

for idx, image in enumerate(images_array):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return_value, corners = cv2.findChessboardCorners(gray, patternSize=grid_size)

    if return_value:
        corners = cv2.cornerSubPix(gray, corners, (5, 5), (-1, -1), criteria)
        corners_array.append(corners.reshape(-1, 2))
    else:
        print(f"Warning: Chessboard corners NOT found in image {idx}")
        corners_array.append(None)

corners_array = np.array(corners_array)

for idx, (image, corners) in enumerate(zip(images_array, corners_array)):
  image_copy = image.copy()
  cv2.drawChessboardCorners(image_copy, grid_size, corners, True)

  plt.figure(figsize=(6.4 * 2, 4.8 * 2))
  plt.title(f"Image {idx} with Chessboard Corners")
  plt.imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))
  plt.axis('off')
  plt.show()

"""## Estimating homographies"""

homography_matrices = []
real_coordinates_array = []

for idx, corners in enumerate(corners_array):
  real_coordinates = np.empty_like(corners)
  for index, corner in enumerate(corners):
      grid_size_cv2 = tuple(reversed(grid_size))
      u_index, v_index = np.unravel_index(index, grid_size_cv2)
      x_mm = (u_index) * square_size
      y_mm = (v_index) * square_size
      real_coordinates[index, :] = [x_mm , y_mm]

  real_coordinates_array.append(real_coordinates)

def compute_homography_matrices(corners_array, coordinates_3D_array):
  homographies = []
  for idx, (corners, coordinates_3D) in enumerate(zip(corners_array, coordinates_3D_array)):
    A = np.empty((0, 9), dtype=float)
    for index, (corner, point_3D) in enumerate(zip(corners, coordinates_3D)):
      u_coord = corner[0]
      v_coord = corner[1]
      x_mm = point_3D[0]
      y_mm = point_3D[1]

      m = np.array([x_mm, y_mm, 1]).reshape(1, 3)
      O = np.array([0, 0, 0]).reshape(1, 3)
      A = np.vstack((A, np.hstack((m, O, -u_coord * m))))
      A = np.vstack((A, np.hstack((O, m, -v_coord * m))))

    U, S, V_transposed = np.linalg.svd(A)
    h = V_transposed.transpose()[:, -1]
    H = h.reshape(3, 3)
    homographies.append(H)
  return np.array(homographies, dtype=object)

homography_matrices = compute_homography_matrices(corners_array, real_coordinates_array)

for idx, H in enumerate(homography_matrices):
    print(f"Image {idx}: Homography Matrix:\n{H}")

for idx, (H, corners, real_coordinates) in enumerate(zip(homography_matrices, corners_array, real_coordinates_array)):
  projected_points = []
  for real_point in real_coordinates:
    X, Y = real_point
    point_homogeneous = np.array([X, Y, 1]).reshape(3, 1)
    projected = H @ point_homogeneous
    u, v, w = projected.flatten()
    projected_points.append((u / w, v / w))

  projected_points = np.array(projected_points)

  image = images_array[idx].copy()
  for projected_point, measured in zip(projected_points, corners):
    u_p, v_p = projected_point
    u_m, v_m = measured
    cv2.circle(image, (int(u_p), int(v_p)), 20, (0, 255, 0), -1)
    cv2.circle(image, (int(u_m), int(v_m)), 17, (0, 0, 255), -1)

  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
  plt.title(f"Image {idx}: Detected vs. Projected Points")
  plt.axis("off")
  plt.show()

"""## Without radial distortion

### Estimate intrinsic and extrinsic parameters
"""

def compute_v_ij(H, i, j):
  return np.array([
    H[0, i] * H[0, j],
    H[0, i] * H[1, j] + H[1, i] * H[0, j],
    H[1, i] * H[1, j],
    H[2, i] * H[0, j] + H[0, i] * H[2, j],
    H[2, i] * H[1, j] + H[1, i] * H[2, j],
    H[2, i] * H[2, j]
  ])

def find_intrinsic_parameters(homography_matrices):
  V = []
  for H in homography_matrices:
    v12 = compute_v_ij(H, 0, 1)
    v11 = compute_v_ij(H, 0, 0)
    v22 = compute_v_ij(H, 1, 1)
    V.append(v12)
    V.append(v11 - v22)
  V = np.array(V)

  _, _, S_transposed = np.linalg.svd(V)
  b = S_transposed.transpose()[:, -1]
  B11, B12, B22, B13, B23, B33 = b
  B = np.array([
        [B11, B12, B13],
        [B12, B22, B23],
        [B13, B23, B33]
    ], dtype=float)
  if not (np.all(np.linalg.eigvals(B) > 0)):
    B *= -1
  L = np.linalg.cholesky(B)
  K = np.linalg.inv(L.transpose())
  K /= K[2, 2]
  return K

K = find_intrinsic_parameters(homography_matrices)
print(f"Estimated Intrinsic Matrix K:\n{K}")

def compute_extrinsic_parameters(H, K):
  K_inv = np.linalg.inv(K)
  h1, h2, h3 = H[:, 0], H[:, 1], H[:, 2]
  lambda_ = 1 / np.linalg.norm(K_inv @ h1)
  r1 = lambda_ * (K_inv @ h1)
  r2 = lambda_ * (K_inv @ h2)
  t = lambda_ * (K_inv @ h3)
  r3 = np.cross(r1, r2)
  R = np.column_stack((r1, r2, r3))
  U, _, V_transposed = np.linalg.svd(R)
  R_orthogonal = U @ V_transposed
  return R_orthogonal, t

rotation_matrices = []
translation_vectors = []

for idx, H in enumerate(homography_matrices):
  H = np.array(H, dtype=np.float64)
  R, t = compute_extrinsic_parameters(H, K)
  print(f"Image {idx}: Rotation Matrix R:\n{R}")
  print(f"Image {idx}: Translation Vector t:\n{t}")
  rotation_matrices.append(R)
  translation_vectors.append(t)

rotation_matrices = np.array(rotation_matrices, dtype=object)
translation_vectors = np.array(translation_vectors, dtype=object)

def compute_projection_matrix(K, R, t):
  t = t.reshape(3, 1)
  Rt = np.hstack((R, t))
  P = K @ Rt
  return P

perspective_projection_matrices = []

for idx, (R, t) in enumerate(zip(rotation_matrices, translation_vectors)):
  P = compute_projection_matrix(K, R, t)
  print(f"Image {idx}: Perspective projection matrix P:\n{P}")
  perspective_projection_matrices.append(P)

perspective_projection_matrices = np.array(perspective_projection_matrices)

"""### Computing the reprojection error"""

chosen_image = cv2.imread(chosenImage)
plt.imshow(chosen_image)

def compute_projected_points(P, coordinates_3D, z_coordinate):
  projected_points = []
  for m_i in coordinates_3D:
    m_i = np.array([m_i[0], m_i[1], z_coordinate, 1], dtype=np.float64)
    p1, p2, p3 = P[0], P[1], P[2]
    u_proj = (p1 @ m_i) / (p3 @ m_i)
    v_proj = (p2 @ m_i) / (p3 @ m_i)
    projected_points.append((u_proj, v_proj))
  return np.array(projected_points)

def compute_reprojection_error(coordinates_2D, projected_points):
  total_error = 0
  for i in range(len(coordinates_2D)):
    u_measured, v_measured = coordinates_2D[i]
    u_proj, v_proj = projected_points[i]
    error = (u_proj - u_measured) ** 2 + (v_proj - v_measured) ** 2
    total_error += error
  return total_error

def compare_points_in_image(image_original, coordinates_2D, projected_points):
  image = image_original.copy()
  coordinates_2D = np.array(coordinates_2D, dtype=np.int32)
  projected_points = np.array(projected_points, dtype=np.int32)
  for (u_measured, v_measured) in coordinates_2D:
    cv2.circle(image, (u_measured, v_measured), 10, (0, 255, 0), -1)
  for (u_proj, v_proj) in projected_points:
    cv2.circle(image, (u_proj, v_proj), 8, (0, 0, 255), -1)

  plt.figure(figsize=(15, 10))
  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
  plt.axis("off")
  plt.show()

projected_points_no_rd = compute_projected_points(perspective_projection_matrices[11], real_coordinates_array[11], 0)
total_reprojection_error = compute_reprojection_error(corners_array[11], projected_points_no_rd)
print("Total Reprojection Error:", total_reprojection_error)
print("Green: Measured Points")
print("Red: Projected Points")
compare_points_in_image(chosen_image, corners_array[11], projected_points_no_rd)

"""### Superimpose a parallelepiped to the calibration images"""

parallelepiped_face = np.array([
    [0, 0],
    [rect_width, 0],
    [rect_width, rect_height],
    [0, rect_height],
], dtype=np.float32)
bottom_z = 0
top_z = parallelepiped_depth

projected_parallelepiped_array = []

for idx, perspective_projection_matrix in enumerate(perspective_projection_matrices):
  corrected_top_z = top_z
  if (square_size == 11):
    if (idx in {2, 4, 8, 9, 10, 14}):
      corrected_top_z = - top_z
  if (square_size == 20):
    if (idx in {0, 1, 7, 11, 13, 14, 15, 16, 17, 19}):
      corrected_top_z = - top_z
  projected_bottom = compute_projected_points(perspective_projection_matrix, parallelepiped_face, bottom_z)
  projected_top = compute_projected_points(perspective_projection_matrix, parallelepiped_face, corrected_top_z)
  projected_parallelepiped = np.vstack((projected_bottom, projected_top))
  projected_parallelepiped_array.append(projected_parallelepiped)

def draw_parallelepiped(image, points_2D):
    points_2D = np.int32(points_2D)
    cv2.polylines(image, [points_2D[:4]], isClosed=True, color=(255, 0, 0), thickness=3)
    cv2.polylines(image, [points_2D[4:]], isClosed=True, color=(0, 255, 0), thickness=3)
    for i in range(4):
        cv2.line(image, tuple(points_2D[i]), tuple(points_2D[i + 4]), (0, 0, 255), thickness=2)

print("Blue: Bottom face")
print("Green: Top face")
print("Red: Sides that join the faces")
for idx, (image, points_2D) in enumerate(zip(images_array, projected_parallelepiped_array)):
        image_with_parallelepiped = image.copy()
        draw_parallelepiped(image_with_parallelepiped, points_2D)
        plt.figure(figsize=(10, 10))
        plt.imshow(cv2.cvtColor(image_with_parallelepiped, cv2.COLOR_BGR2RGB))
        plt.title(f"Image {idx}: Parallelepiped Superimposed")
        plt.axis('off')
        plt.show()

"""## With radial distortion"""

projected_points_array = []

for (perspective_projection_matrix, real_coordinates) in zip(perspective_projection_matrices, real_coordinates_array):
  projected_points = compute_projected_points(perspective_projection_matrix, real_coordinates, 0)
  projected_points_array.append(projected_points)
projected_points_array = np.array(projected_points_array)


def estimate_radial_distortion(projected_points_array, measured_coordinates_2D_array, K):
  u0, v0 = K[0, 2], K[1, 2]
  alpha_u = K[0, 0]
  sin_theta = 1 / np.sqrt(1 + (K[0,1] / K[0,0]) ** 2)
  alpha_v = K[1, 1] * sin_theta

  A = []
  b = []
  for (projected_points, measured_coordinates_2D) in zip(projected_points_array, measured_coordinates_2D_array):
    for (projected_point, point_2D) in zip(projected_points, measured_coordinates_2D):
      u, v = projected_point
      u_hat, v_hat = point_2D
      r_d_squared = ((u - u0) / alpha_u) ** 2 + ((v - v0) / alpha_v) ** 2
      r_d_fourth = r_d_squared ** 2

      A.append([(u - u0) * r_d_squared, (u - u0) * r_d_fourth])
      b.append(u_hat - u)
      A.append([(v - v0) * r_d_squared, (v - v0) * r_d_fourth])
      b.append(v_hat - v)
  A = np.array(A, dtype=np.float64)
  b = np.array(b, dtype=np.float64)

  k, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
  return k[0], k[1]

k1, k2 = estimate_radial_distortion(projected_points_array, corners_array, K)
print(f"Estimated k1: {k1}, k2: {k2}")

def compensate_radial_distortion(measured_2D_points_array, k1, k2, K, max_iters=10, tol=1e-6):
  corrected_2D_points_array = []
  u0, v0 = K[0, 2], K[1, 2]
  alpha_u = K[0, 0]
  sin_theta = 1 / np.sqrt(1 + (K[0,1] / K[0,0]) ** 2)
  alpha_v = K[1, 1] * sin_theta

  for measured_2D_points in measured_2D_points_array:
    corrected_2D_points = np.zeros_like(measured_2D_points)

    for i, (u_hat, v_hat) in enumerate(measured_2D_points):
      x_d = (u_hat - u0) / alpha_u
      y_d = (v_hat - v0) / alpha_v

      x, y = float(x_d), float(y_d)

      for _ in range(max_iters):
        r2 = x**2 + y**2
        radial_factor = 1 + k1 * r2 + k2 * r2**2

        fx = x * radial_factor - x_d
        fy = y * radial_factor - y_d

        if np.linalg.norm([fx, fy]) < tol:
          break

        dFx_dx = 1 + k1 * (3 * x**2 + y**2) + k2 * (5 * x**4 + 6 * x**2 * y**2 + y**4)
        dFx_dy = x * (2 * k1 * y + 4 * k2 * y * r2)
        dFy_dx = y * (2 * k1 * x + 4 * k2 * x * r2)
        dFy_dy = 1 + k1 * (x**2 + 3 * y**2) + k2 * (x**4 + 6 * x**2 * y**2 + 5 * y**4)


        J = np.array([[dFx_dx, dFx_dy], [dFy_dx, dFy_dy]])
        F = np.array([-fx, -fy])
        delta = np.linalg.solve(J, F)
        x += delta[0]
        y += delta[1]

      corrected_2D_points[i] = [u0 + alpha_u * x, v0 + alpha_v * y]

    corrected_2D_points_array.append(corrected_2D_points)

  return np.array(corrected_2D_points_array)

updated_K = K.copy()
prev_k1, prev_k2 = 0, 0
tolerance = 1e-4
max_iters = 5

for iteration in range(max_iters):

  corrected_2D_points_array = compensate_radial_distortion(corners_array, k1, k2, updated_K)
  updated_homography_matrices = compute_homography_matrices(corrected_2D_points_array, real_coordinates_array)
  updated_K = find_intrinsic_parameters(updated_homography_matrices)

  updated_rotation_matrices = []
  updated_translation_vectors = []

  for idx, H in enumerate(updated_homography_matrices):
    H = np.array(H, dtype=np.float64)
    updated_R, updated_t = compute_extrinsic_parameters(H, updated_K)
    updated_rotation_matrices.append(updated_R)
    updated_translation_vectors.append(updated_t)

  updated_rotation_matrices = np.array(updated_rotation_matrices, dtype=object)
  updated_translation_vectors = np.array(updated_translation_vectors, dtype=object)

  updated_perspective_projection_matrices = []

  for idx, (updated_R, updated_t) in enumerate(zip(updated_rotation_matrices, updated_translation_vectors)):
    updated_P = compute_projection_matrix(updated_K, updated_R, updated_t)
    updated_perspective_projection_matrices.append(updated_P)

  updated_perspective_projection_matrices = np.array(updated_perspective_projection_matrices)

  updated_projected_points_array = []

  for (updated_P, real_coordinates) in zip(updated_perspective_projection_matrices, real_coordinates_array):
    updated_projected_points = compute_projected_points(updated_P, real_coordinates, 0)
    updated_projected_points_array.append(updated_projected_points)
  updated_projected_points_array = np.array(updated_projected_points_array)

  k1, k2 = estimate_radial_distortion(updated_projected_points_array, corrected_2D_points_array, updated_K)

  if abs(k1 - prev_k1) < tolerance and abs(k2 - prev_k2) < tolerance:
    break
  prev_k1, prev_k2 = k1, k2

print(f"Final Intrinsics:\n{updated_K}")
print(f"Final k1, k2: {k1}, {k2}")

"""### Total reprojection error"""

distorted_projected_points = []
u0, v0 = updated_K[0, 2], updated_K[1, 2]
alpha_u = updated_K[0, 0]
sin_theta = 1 / np.sqrt(1 + (updated_K[0,1] / updated_K[0,0]) ** 2)
alpha_v = K[1, 1] * sin_theta

total_reprojection_error_rd = compute_reprojection_error(corners_array[11], updated_projected_points_array[11])

print("Total Reprojection Error:", total_reprojection_error_rd)
print("Green: Measured Points")
print("Red: Projected Points")

compare_points_in_image(chosen_image, corners_array[11], updated_projected_points_array[11])